{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic: Cross Validation in predictive modeling\n",
    "\n",
    "\n",
    "## Problem\n",
    "\n",
    "When you do `train-test-split` you are sampling randomly to identify the train and test datasets.\n",
    "\n",
    "![img](train-test-examp.png)\n",
    "\n",
    "But what about **sampling error**? What if you get a **BAD SAMPLE**?!\n",
    "\n",
    "![bad](https://media.giphy.com/media/cJjQJWU70DSuHzx4oR/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Task\n",
    "![map](map.png) \n",
    "\n",
    "Build a multivariate Ordinary Least Squares regression model to predict \"TARGET_deathRate\"with a more robust model validation method, cross-validation.<br>\n",
    "We have data aggregated from a number of sources including the American Community Survey (census.gov), clinicaltrials.gov, and cancer.gov. Most of the data preparation process can be viewed here.\n",
    "\n",
    "\n",
    "## Learning Goals:\n",
    "\n",
    "- Describe the elements of  K-fold Cross validation \n",
    "- Recognize how K-fold cross validation is superior to normal validation testing\n",
    "- Apply K-fold cross validation to a dataset\n",
    "- Apply K-fold cross validation to Module 1 project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation\n",
    "Let us talk about `training` and `testing.`\n",
    "\n",
    "![train-test](why-train-test.png)\n",
    "\n",
    "We split to prevent:\n",
    "\n",
    "![fit-pit](overfit_underfit.png)\n",
    "(found on [this blog](https://rmartinshort.jimdo.com/2019/02/17/overfitting-bias-variance-and-leaning-curves/)). \n",
    "\n",
    "But what if by random chance of your training dataset split - your training data isn't representative? what if it includes some wacky data?\n",
    "\n",
    "![but what if](bad-split.png)\n",
    "\n",
    "k-fold averages that out, and also keeps from “overfitting” and “underfitting.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goal 1: Describe the elements of K-fold Cross validation \n",
    "\n",
    "In the context of modeling, K-fold cross validation sits under the Stage 6- Predictive Modeling, in the 7 stage Data Science Lifecycle.\n",
    "\n",
    "![chart](chart.png)\n",
    "\n",
    "K-fold cross validation essentially helps us increase the accuracy of any Machine learning model. It does this by taking the average of the results of training and testing data from given dataset. This in turn is by dividing the dataset into several (“k”) folds. Then, Training data on “k-1” folds and testing on “kth” fold. Repeat this “k” times and average the result.\n",
    "\n",
    "![cross-val](cross-val-graphic.png)\n",
    "(graphic from [here](https://towardsdatascience.com/cross-validation-70289113a072) )\n",
    "\n",
    "We can compare the resultant accuracy by taking the average of accuracy calculated during each of the folds. This tends to give a more real picture of the machine learning model performance. \n",
    "\n",
    "The cross validation technique can be used to compare the performance of different machine learning models on the same data set. To understand this point better, let us consider the following example.\n",
    "\n",
    "Go through [this blog](https://towardsdatascience.com/5-reasons-why-you-should-use-cross-validation-in-your-data-science-project-8163311a1e79) to hit the topic home.\n",
    "\n",
    "## Learning Goal 2:  Explain to Greg\n",
    "![img2](thinking.jpeg)\n",
    "\n",
    "You've hired Greg to build models for you. He's stressed and trying to tell you there isn't enough time to do a cross validation and that one train-test split should be enough.\n",
    "\n",
    "Write down what you would say to Greg and then tell it to your neighbor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goal 3: Applying k-fold cross validation\n",
    "\n",
    "### Try the code in each of these articles:\n",
    "\n",
    "### One half of room:\n",
    "This is a good tech blog:\n",
    "\n",
    "[this blog is a good one](https://machinelearningmastery.com/k-fold-cross-validation/)\n",
    "\n",
    "### Other half of room:\n",
    "[another good example](https://medium.com/datadriveninvestor/k-fold-cross-validation-6b8518070833)\n",
    "\n",
    "\n",
    "### Task: \n",
    "Write the most important  parts of code from each post on the board & then discuss\n",
    "\n",
    "- What did you need to specify?\n",
    "- What new libraries did you use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model to predict cancer\n",
    "\n",
    "\n",
    "```\n",
    "cancer_rates = pd.read_csv('https://query.data.world/s/5ylxfjp6oymzhuhhzwmlbqxzcw6etz')\n",
    "\n",
    "households = pd.read_csv('https://download.data.world/s/3nopgtdm2fwjgidovkostutkfitlps')\n",
    "```\n",
    "\n",
    "[Here is the documentatiopn](https://data.world/exercises/linear-regression-exercise-1/workspace/data-dictionary) for this data.\n",
    "\n",
    "Integrate this new knowledge of k-fold cross validation to build a model and calculate the average performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer=pd.read_csv(\"https://query.data.world/s/5ylxfjp6oymzhuhhzwmlbqxzcw6etz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3047 entries, 0 to 3046\n",
      "Data columns (total 30 columns):\n",
      "avganncount               3047 non-null float64\n",
      "avgdeathsperyear          3047 non-null int64\n",
      "target_deathrate          3047 non-null float64\n",
      "incidencerate             3047 non-null float64\n",
      "medincome                 3047 non-null int64\n",
      "popest2015                3047 non-null int64\n",
      "povertypercent            3047 non-null float64\n",
      "studypercap               3047 non-null float64\n",
      "binnedinc                 3047 non-null object\n",
      "medianage                 3047 non-null float64\n",
      "medianagemale             3047 non-null float64\n",
      "medianagefemale           3047 non-null float64\n",
      "geography                 3047 non-null object\n",
      "percentmarried            3047 non-null float64\n",
      "pctnohs18_24              3047 non-null float64\n",
      "pcths18_24                3047 non-null float64\n",
      "pctbachdeg18_24           3047 non-null float64\n",
      "pcths25_over              3047 non-null float64\n",
      "pctbachdeg25_over         3047 non-null float64\n",
      "pctunemployed16_over      3047 non-null float64\n",
      "pctprivatecoverage        3047 non-null float64\n",
      "pctempprivcoverage        3047 non-null float64\n",
      "pctpubliccoverage         3047 non-null float64\n",
      "pctpubliccoveragealone    3047 non-null float64\n",
      "pctwhite                  3047 non-null float64\n",
      "pctblack                  3047 non-null float64\n",
      "pctasian                  3047 non-null float64\n",
      "pctotherrace              3047 non-null float64\n",
      "pctmarriedhouseholds      3047 non-null float64\n",
      "birthrate                 3047 non-null float64\n",
      "dtypes: float64(25), int64(3), object(2)\n",
      "memory usage: 714.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cancer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cancer=df_cancer.dropna(axis=1, how=\"all\")\n",
    "# df_cancer=df_cancer.drop(['pctsomecol18_24','pctemployed16_over','pctprivatecoveragealone'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3047 entries, 0 to 3046\n",
      "Data columns (total 30 columns):\n",
      "avganncount               3047 non-null float64\n",
      "avgdeathsperyear          3047 non-null int64\n",
      "target_deathrate          3047 non-null float64\n",
      "incidencerate             3047 non-null float64\n",
      "medincome                 3047 non-null int64\n",
      "popest2015                3047 non-null int64\n",
      "povertypercent            3047 non-null float64\n",
      "studypercap               3047 non-null float64\n",
      "binnedinc                 3047 non-null object\n",
      "medianage                 3047 non-null float64\n",
      "medianagemale             3047 non-null float64\n",
      "medianagefemale           3047 non-null float64\n",
      "geography                 3047 non-null object\n",
      "percentmarried            3047 non-null float64\n",
      "pctnohs18_24              3047 non-null float64\n",
      "pcths18_24                3047 non-null float64\n",
      "pctbachdeg18_24           3047 non-null float64\n",
      "pcths25_over              3047 non-null float64\n",
      "pctbachdeg25_over         3047 non-null float64\n",
      "pctunemployed16_over      3047 non-null float64\n",
      "pctprivatecoverage        3047 non-null float64\n",
      "pctempprivcoverage        3047 non-null float64\n",
      "pctpubliccoverage         3047 non-null float64\n",
      "pctpubliccoveragealone    3047 non-null float64\n",
      "pctwhite                  3047 non-null float64\n",
      "pctblack                  3047 non-null float64\n",
      "pctasian                  3047 non-null float64\n",
      "pctotherrace              3047 non-null float64\n",
      "pctmarriedhouseholds      3047 non-null float64\n",
      "birthrate                 3047 non-null float64\n",
      "dtypes: float64(25), int64(3), object(2)\n",
      "memory usage: 714.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cancer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-31c1261231a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcv_5_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"neg_mean_squared_error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcv_10_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"neg_mean_squared_error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcv_20_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"neg_mean_squared_error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X=\n",
    "y=\n",
    "\n",
    "cv_5_results = np.mean(cross_val_score(linreg, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "cv_10_results = np.mean(cross_val_score(linreg, X, y, cv=10, scoring=\"neg_mean_squared_error\"))\n",
    "cv_20_results = np.mean(cross_val_score(linreg, X, y, cv=20, scoring=\"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment\n",
    "\n",
    "Did they achieve all the learning goals from the start? How do you confirm? You can use many different methods:\n",
    "\n",
    "Review questions? (make into quiz)\n",
    "\n",
    "- What is “training” and “testing” \n",
    "- What is underfitting?\n",
    "- What is overfitting?\n",
    "- What is the data science lifecycle? (students should be able to articulate the 7 steps in the - pie chart above)\n",
    "- What is k-fold cross validation?\n",
    "\n",
    "\n",
    "Why is it useful?\n",
    "\n",
    "### Reflection/Key Takeaways\n",
    "\n",
    "\n",
    "In machine learning, it is always a good idea to play around with different predictive models and their parameters to arrive at the best choice. Fine-tuning your machine learning model is helpful in achieving good results, and of course, cross validation helps you know if you are on the right track to get a good predictive model.\n",
    "\n",
    "\n",
    "_Limitations of Cross Validation_ <br>\n",
    "For cross validation to give some meaningful results, the training set and the validation set are required to be drawn from the same population. Also, human biases need to be controlled, or else cross validation will not be fruitful.\n",
    "\n",
    "_**Other Applications**_\n",
    "\n",
    "_Compare Performance_<br>\n",
    "Suppose you want to make a classifier for the MNIST data set, which consists of hand-written numerals from 0 to 9. You are considering using either K Nearest Neighbours (KNN) or Support Vector Machine (SVM). To compare the performance of the two machine learning models on the given data set, you can use cross validation. This will help you determine which predictive model you should choose working with for the MNIST data set.\n",
    "Cross validation can also be used for selecting suitable parameters. The example mentioned below will illustrate this point well.\n",
    "\n",
    "_Fine-tune Parameters_<br>\n",
    "Suppose you have to build a K Nearest Neighbours (KNN) classifier for the MNIST data set. To use this classifier, you should provide an appropriate value of the parameter k to the classifier. Choosing the value of k intuitively is not a good idea (beware of overfitting!). You can play around with different values of the parameter k and use cross validation to estimate the performance of the predictive model corresponding to each k. You should finally go ahead with the value of k that gives the best performance of the predictive model on the given data set.\n",
    "For the K Nearest Neighbours (KNN) classifier, you can even choose different metrics (default is ‘minkowski’ if you use ‘KNeighborsClassifier’ of sklearn). So you can use cross validation to determine which metric is the best for the data set you have.\n",
    "\n",
    "_References_\n",
    "- https://machinelearningmastery.com/k-fold-cross-validation/\n",
    "- https://towardsdatascience.com/5-reasons-why-you-should-use-cross-validation-in-your-data-science-project-8163311a1e79\n",
    "- https://www.researchgate.net/post/What_is_the_purpose_of_performing_cross-validation\n",
    "- https://medium.com/datadriveninvestor/k-fold-cross-validation-6b8518070833\n",
    "- https://www.cs.tau.ac.il/~nin/Courses/NC05/pr_l13.pdf\n",
    "- https://magoosh.com/data-science/k-fold-cross-validation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
